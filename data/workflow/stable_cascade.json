{
    "3": {
      "inputs": {
        "seed": 981316712107179,
        "steps": 4,
        "cfg": 4,
        "sampler_name": "euler_ancestral",
        "scheduler": "simple",
        "denoise": 1,
        "model": [
          "41",
          0
        ],
        "positive": [
          "6",
          0
        ],
        "negative": [
          "7",
          0
        ],
        "latent_image": [
          "34",
          0
        ]
      },
      "class_type": "KSampler",
      "_meta": {
        "title": "KSampler"
      }
    },
    "6": {
      "inputs": {
        "text": "a photo of a rich young person, exposed face, looking at the camera, ultra quality, sharp focus, tack sharp, dof, 8K UHD, hdr, high resolution",
        "clip": [
          "41",
          1
        ]
      },
      "class_type": "CLIPTextEncode",
      "_meta": {
        "title": "CLIP Text Encode (Prompt)"
      }
    },
    "7": {
      "inputs": {
        "text": "text, watermark",
        "clip": [
          "41",
          1
        ]
      },
      "class_type": "CLIPTextEncode",
      "_meta": {
        "title": "CLIP Text Encode (Prompt)"
      }
    },
    "8": {
      "inputs": {
        "samples": [
          "33",
          0
        ],
        "vae": [
          "42",
          2
        ]
      },
      "class_type": "VAEDecode",
      "_meta": {
        "title": "VAE Decode"
      }
    },
    "9": {
      "inputs": {
        "filename_prefix": "ComfyUI",
        "images": [
          "8",
          0
        ]
      },
      "class_type": "SaveImage",
      "_meta": {
        "title": "Save Image"
      }
    },
    "33": {
      "inputs": {
        "seed": 268870717594544,
        "steps": 4,
        "cfg": 1.1,
        "sampler_name": "euler_ancestral",
        "scheduler": "simple",
        "denoise": 1,
        "model": [
          "42",
          0
        ],
        "positive": [
          "36",
          0
        ],
        "negative": [
          "7",
          0
        ],
        "latent_image": [
          "34",
          1
        ]
      },
      "class_type": "KSampler",
      "_meta": {
        "title": "KSampler"
      }
    },
    "34": {
      "inputs": {
        "width": 1024,
        "height": 1024,
        "compression": 42,
        "batch_size": 16
      },
      "class_type": "StableCascade_EmptyLatentImage",
      "_meta": {
        "title": "StableCascade_EmptyLatentImage"
      }
    },
    "36": {
      "inputs": {
        "conditioning": [
          "6",
          0
        ],
        "stage_c": [
          "3",
          0
        ]
      },
      "class_type": "StableCascade_StageB_Conditioning",
      "_meta": {
        "title": "StableCascade_StageB_Conditioning"
      }
    },
    "41": {
      "inputs": {
        "ckpt_name": "stable_cascade_stage_c.safetensors"
      },
      "class_type": "CheckpointLoaderSimple",
      "_meta": {
        "title": "Load Checkpoint"
      }
    },
    "42": {
      "inputs": {
        "ckpt_name": "stable_cascade_stage_b.safetensors"
      },
      "class_type": "CheckpointLoaderSimple",
      "_meta": {
        "title": "Load Checkpoint"
      }
    }
  }